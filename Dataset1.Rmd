---
title: "Individual assignment"
author: 
  - Jon Ingi Hlynsson <sub><jon.ingi.hlynsson@gmail.com><sub>
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc_depth: 3
    toc: yes
    toc_float: no
    code_folding: hide
    fig_caption: yes
    theme: flatly
    highlight: textmate
bibliography: refs.bib
citation-style: apa-annotated-bibliography.csl
---

<style>

/* NOTE: I opted to do this css specification in the file itself so I don't have 
to submit an extra .css file for this assignment - under regular circumstances 
this is NOT good code. */

html{
scroll-behavior: smooth; /* Set the scroll behavior to smooth */
}

</style>

```{r setup and packages, include=FALSE}
## NOTE: In the instructions, it says to ONLY do a results section.
# ------ Thus, a general conclusion was not included in this paper.


# The following `knitr` code is included by default in markdown - it sets the 
# default behaviour of all my chunks to echo, meaning that the code is shown
knitr::opts_chunk$set(echo = TRUE) 

## clean the environment -----
rm(list = ls(all=T)) # remove all variables (all=T takes care of hidden objects)
graphics.off() # turn off plots
cat("\014") # clear the console ("\014" refers to the "L" key on the keyboard)
## ----

## an error message and the fix ------------------------------------------------
## I sometimes get the error:

# Error in gregexpr(calltext, singleline, fixed = TRUE) : 
# regular expression is invalid UTF-8

## the following code usually fixes it:
# .rs.restartR() # this restarts the session

## However I've also had to go into *file* and *reopen with Encoding* and choose 
#  UTF-8
# the following code can also does that
# options(encoding = "UTF-8")

# This extra information is added here as a comment to make readers aware of the
# potential that this has happened on my end but likewise has a fix.
## -----------------------------------------------------------------------------


## import packages ----
library(tidyverse) # for pipe friendly operations and ggplot
library(ggpubr) # for convenient plotting 
library(kableExtra) # for nice tables
library(knitr) # for kable function and markdown output
library(rstanarm) # for Bayesian models 
## ---

## Set working directory ----
# Remember to set the working directory to the RELEVEANT position
```

```{r CODE BOOK for simple data set, include = TRUE,  class.source = "fold-hide", echo=F}
## CODE BOOK - Variable names ----------------------------------------------

# id = uniqe names for each participant
# soundscape_type: N = nature, U = urban
# bds_pre = Pre-test results of the back-ward digit span task (BDS)
# bds_post = Post-test results of the back-ward digit span task (BDS)
# dnb_pre = Pre-test results of the dual n-back task (DNB)
# dnb_post = Post-test results of the dual n-back task (DNB)
# guessed_purpose = Whether the participant guessed (1) or not (0) the 
#------------------ purpose of the experiment
## -------------------------------------------------------------------------
```


# An exposure to a natural soundscape improves cognitive performance on cognitive tasks when compared to urban soundscapes


The following paper is made using ***RStudio***^[A language and environment for statistical computing] [@rcoreteamLanguageEnvironmentStatistical2021] and RMarkdown [@xieMarkdownCookbook2020]. In it I will examine whether exposure to sounds from nature **improves performance** on cognitive tests measuring directed attention. 

I will work on a subset of @vanhedgerCricketChirpsCar2019 data from the article *Of cricket chirps and car horns: The effect of nature sounds on cognitive performance*, data available on the Open Science Framework (https://osf.io/5ub4c/)^[See Apendix I for how the subset was derived].

@vanhedgerCricketChirpsCar2019 hypothesised that individuals exposed to *natural soundscapes* would perform better on the cognitive tasks compared to individuals exposed to urban soundscapes.
<br>

## Data screening

Initial data screening reviled no missing values, see table 1.1 for descriptive statistics.

```{r Read in data, results='hide', class.source = "fold-hide", echo=F}
## Read in data ----

# NOTE: I opted to read the data in via a link to my github to make the document
# reproducible in a manner that only requires an internet connection to run the
# script, i.e., without having to download the data on one's individual computer
# It would perhaps have been preferable to read the data in from a folder on the
# computer but that presupposes that the user can set working directory to an 
# appropriate place and thus this method was chosen insted

d_full <- read.table("https://raw.githubusercontent.com/JonHlynsson/PSMT59-Statistics-I/master/data/d1_soundscape.txt", 
                     header = T, sep = ",")

## Alternative way to read in the data is in the line below BUT commented out
# d_full <- read_table("data/d1_soundscape.txt", header = T, sep = ",")
```

```{r Check for missing values, class.source = "fold-hide", echo=F, results='hide'}
# Check for missing values in the dataset
sum(is.na(d_full)) 
```

```{r and check structure and summary of dataset, results='hide', echo=F}
head(d_full)
str(d_full)
summary(d_full)
d_full_descriptives <- psych::describe(d_full) # create desc stats variable
summary(as.factor(d_full$guessed_purpose)) # - here I can see how many guessed the purpose
```


```{r, echo=FALSE}
# give rows meaningful names ----
row.names(d_full_descriptives) <- c("ID-number", 
                                    "Soundscape type",
                                    "BDS pretest",
                                    "BDS posttest",
                                    "DNB pretest",
                                    "DNB posttest",
                                    "Guessed purpose of experiment")

# select relevant columns ----
d_full_stats <- d_full_descriptives %>% 
  select(n, mean, sd, median, min, max, se) 

# give columns relevant names ----
colnames(d_full_stats) <- c("N", "Mean", "Standard\n\ndeviation", "Median", "Min", 
                            "Max", "Standard\n\nerror")

# print table -----
d_full_stats %>%
  kable(digits = 2,
        align = "c",
        caption = "Descriptive statistics") %>% kable_classic() %>% 
  kable_styling(full_width = F, html_font = "Times") %>% 
  footnote(general = "BDS refers to the back-ward digit span task and DNB refers to the dual n-back task.\n\n", 
           footnote_as_chunk = T, fixed_small_size = T) %>% 
  add_footnote(c("BDS and DNB are assumed to be on an interval scale.", 
                 "In total, 17 participants guessed the purpose of the experiment."), 
               notation = "alphabet")
```


<br> The attentional measures `DNB` and `BDS` will be assumed to be on an interval scale; `BDS` was scored as number of correct trials, and `DNB` was turned into d-prime ($d{\prime}$). Thus, for both measures, zero is *at least somewhat* meaningful (indicative of a ratio scale), justifying interval scale treatment.
<br><br>

```{r Create a new data set with all participants, echo=F, results='hide'}
## Regarding the construction of a new dataset from d_full ---- 

# The data is applicable to a data-analysis. First a new dataset needs to be 
# constructed with the aim of binding together the cognitive measures 
# back-ward digit span task (DBS) and `dual n-back task (DNB)`. 
# Thereafter, the `dnb` and `bds` variables need to be z-scored to make the two 
# attentional cognitive measures comparable. Finally, the z-scored variables 
# dnb and bds can be combined.

## ----

## Predata selection ----
d_full_pre <- d_full[, c(1, 2, 3, 5, 7)] # select pretest data
d_full_pre$testing <- rep(0, nrow(d_full_pre)) # add dummy variable to indicate 
names(d_full_pre) <- c("id", 
                       "soundscape_type", 
                       "bds", 
                       "dnb",
                       "guessed_purpose", 
                       "testing") # rename variables because I already have an
#                                   indication variable
head(d_full_pre) # sanity check 
str(d_full_pre) # sanity check 
## ----


## Postdata selection ----
d_full_post <- d_full[, c(1, 2, 4, 6, 7)] # select postdata
d_full_post$testing <- rep(1, nrow(d_full_post)) # add dummy var to indicate
names(d_full_post) <- c("id", 
                        "soundscape_type", 
                        "bds", 
                        "dnb", 
                        "guessed_purpose", 
                        "testing") # rename variables because I already have an
#                                    indication variable
head(d_full_post) # sanity check
str(d_full_post) # sanity check
## ----


## Create a new combined dataset with r-bind ----
d <- rbind(d_full_pre, d_full_post)
head(d) # sanity check
summary(d) # sanity check
str(d) # sanity check
## ----

## remove pre and post data placeholder datasets to clear memory  ----
rm(d_full_pre)
rm(d_full_post)
## ----


## Make id, soundscape_type, guessed_purpose, and post as factors ----
d$id <- factor(d$id)
d$soundscape_type <- factor(d$soundscape_type, labels = c("Natural", "Urban"))
d$guessed_purpose <- factor(d$guessed_purpose, labels = c("No", "Yes"))
d$testing <- factor(d$testing, labels = c("Pretest", "Posttest"))

head(d) # sanity check
str(d) # sanity check
summary(d) # sanity check 
## ----


## Create z-score function ----
z_score <- function(x){
  out <- (x - mean(x, na.rm = TRUE))/sd(x, na.rm = TRUE)
  out
}
## ----


## z-score the difference score ----
d$zDNB <- z_score(d$dnb)
d$zBDS <- z_score(d$bds)
head(d) # sanity check
## ----


## combine z-variables ----
d$CogTest <- (d$zDNB + d$zBDS)/2
head(d) # sanity check
str(d) # sanity check
summary(d) # sanity check
```

## Replication analysis

An interaction plot replicates @vanhedgerCricketChirpsCar2019 results, see figure 1.1. It should be noted that @vanhedgerCricketChirpsCar2019 perform two analysis's; (a) an ANOVA with all participants, and (b) an ANOVA with naïve participants only^[Relevant ANOVA descriptives can be found in [supplementary table 1.](https://jonhlynsson.github.io/PSMT59-Statistics-I/sup.html)].


```{r, echo=F, fig.cap="Effects plot replicating @vanhedgerCricketChirpsCar2019", results='hide', fig.show="hold", out.width="75%", fig.align='center'}
## First I need to define a new dataset with only the naïve participants ----

## new dataset with only naïve ----

# First select all cases where guessed purpose = No from dataset d
# but exclude the variables made for full set 

# First create new datase n_d from d where guessed purpose = No
# then select relevant variables with the select function from tidyverse
n_d <- d[d$guessed_purpose=="No", ] %>% 
  select(id, guessed_purpose, bds, dnb, testing, soundscape_type) 

head(n_d) # sanity check

# now create a new z-score for bds and dnb ----
n_d$zDNB_naive <- z_score(n_d$dnb) 
n_d$zBDS_naive <- z_score(n_d$bds)
head(n_d) # sanity check

## combine z-variables ----
n_d$CogTest <- (n_d$zDNB + n_d$zBDS)/2
head(n_d) # sanity check

## Draw figures ----
# create position dodge (pd) to avoid plot overlay, i.e., avoid overplotting
pd <- position_dodge(0.3) 

# plot for full dataset created
plot_full <- ggline(d, x = "testing", y = "CogTest", color = "soundscape_type",
               add = c("mean_se"),
               palette = c("#058d18", "#cf5474"),
               ggtheme = theme_pubr(),
               main = "All participants",
               xlab = "Time",
               ylab = "Compostite score (z)",
               ylim = range(-0.4, 0.6),
               legend.title = "Soundscape type",
               font.main = c("italic"),
               position = pd, 
               shape = "soundscape_type") 

# plot for naive participants created
plot_naive <- ggline(n_d, x = "testing", y = "CogTest", color = "soundscape_type",
               add = c("mean_se"),
               palette = c("#058d18", "#cf5474"),
               ggtheme = theme_pubr(),
               main = "Naïve participants", 
               xlab = "Time",
               ylab = "Compostite score (z)",
               ylim = range(-0.4, 0.6),
               legend.title = "Soundscape type",
               font.main = c("italic"),
               position = pd,
               shape = "soundscape_type")

## arrange figures together in a new variable to print in the file ----
figure1 <- ggarrange(plot_full, plot_naive, common.legend = TRUE, 
                    legend = "top", nrow = 1, widths = c(3, 3))

# Print figure ----
figure1
```

As figure 1.1 shows, there's an interaction between time of testing (i.e., pre-test and post-test) that doesn't appear to differ substantially between naïve and non-naïve participants. However, larger standard errors are in the naïve group indicate *more uncertainty* in the naïve group.
<br><br>


## Bayesian replication 
```{r Using difference scores to better interperate the results, results='hide', echo=F}

# replicate d_full ----
d2 <- d_full

# create difference scores ----
d2$bds_diff <- (d2$bds_post - d2$bds_pre) 
d2$dnb_diff <- (d2$dnb_post - d2$dnb_pre)

# Z-scoring ----
# z score the difference scores separately to be able to add the two attentional 
# tasks together

d2$bds_diff_Z <- z_score(d2$bds_diff)
d2$dnb_diff_Z <- z_score(d2$dnb_diff)


round(mean(d2$dnb_diff_Z), 5) # sanity check - we want the value 0
round(mean(d2$bds_diff_Z), 5) # sanity check - we want the value 0

sd(d2$bds_diff_Z) # sanity check - should give the value 1
sd(d2$dnb_diff_Z) # sanity check - should give the value 1


# create composite variable from the difference scores ----
d2$CogTest <- (d2$bds_diff_Z + d2$dnb_diff_Z)/2

# make soundscape a factor and let Urban be the reference group ----
d2$soundscape_type <- factor(d2$soundscape_type, levels = c("U", "N"))

# do a crude linear model ----
crude <- stan_glm(CogTest ~ soundscape_type, 
                  data = d2, 
                  refresh = F, 
                  seed = 1995)
summary(crude) # model inspection
round(coef(crude), 2) # model inspection
round(posterior_interval(crude, prob = .89), 2) # model inspection
```


```{r, results='hide', echo=F}
# repeat info from code book for convenience to reader of this code ----
# guessed_purpose = Whether the participant guessed (1) or not (0) the 
#------------------ purpose of the experiment

# make guessed purpose a factor ----
d2$guessed_purpose <- factor(d2$guessed_purpose, 
                             levels = c("1", "0"),
                             labels = c("Not-naïve", "Naïve"))  

# do an adjusted model
adjusted <- stan_glm(CogTest ~ soundscape_type + guessed_purpose, 
                     data = d2, 
                     refresh = F, 
                     seed = 1995)

summary(adjusted) # model inspection
round(coef(crude), 2)  # CRUDE model inspection
round(posterior_interval(crude, prob = .89), 2) # CRUDE model inspection
round(coef(adjusted), 2)  # ADJUSTED model inspection
round(posterior_interval(adjusted, prob = .89), 2) # ADJUSTED model inspection


## Data table preparation ----
# create variable that holds all info about both models ----
Models <- rbind(crude=round(posterior_interval(crude, prob = .89), 2), 
                adjusted=round(posterior_interval(adjusted, prob = .89), 2))

# give rows meaningful names ----
row.names(Models) <- c("Intercept", "Soundscape Natural", "Sigma", 
                       "Intercept", "Soundscape Natural", "Naïve", "Sigma")


Models[c(1,2,4,5,6), ] # sanity check to see how output looks like without sigma

```

```{r, echo=F}
# print the table variable created above with kable and kable extra
Models[c(1,2,4,5,6), ] %>% 
  kable(caption = "89% Compatability intervals for crude and adjusted models") %>% 
  kable_classic(html_font = "Times") %>% 
  kable_styling(full_width = F, position = "float_right") %>% 
  ## kableExtra:: is used to avoid conflict of packages 
  kableExtra::group_rows(group_label = "Crude model", start_row = 1, 
                         end_row = 2) %>% 
  kableExtra::group_rows(group_label = "Adjusted model", start_row = 3, 
                         end_row = 5)
```
To better get an idea of the effect apparent in figure 1.1, soundscape type was regressed on a difference score between pre- and posttest using a Bayesian model. The results showed that participants exposed to a natural soundscape performed better on attentional measures. The data is compatible with an increase of 0.48 standardized units in performance among participants.

However, since point-estimates can be deceiving, a 89% compatibility interval was calculated for the standardized improvement. The 89% cutoff was chosen as an alternative to the 95% custom because it's a Prime number [@mcelreathStatisticalRethinkingBayesian2020].

The data is most compatible with ranges from 0.20 to 0.74, given the data and statistical model. Thus, the data indicates that a naturalistic soundscape has the potential to affect cognitive capabilities, as measured by the `DNB` and `BDS` attentional tasks described above. 

$\mathrm{Cognitive\:Performance} \sim \mathrm{Soundscape\:Type}$ is a crude model and doesn't account for participant nativity. Thus a model with naïvety and soundscape type could add accuracy to the predictions^[i.e., $\mathrm{Cognitive\:Performance} \sim \mathrm{Soundscape\:Type}\:+\:\mathrm{Participant\:Natïvity}$].

However, it's necessary to keep in mind that the pattern in figure 1.1 did not differ substantially between those who were naïve to the hypothesis and those who were not. Table 1.2 shows a comparison between the aforementioned models^[Supplementary table 2 shows the point estimates].
<br><br>

### Posterior distribution plots

To visualize the posterior distributions, a scatterplot with a regression line and regression line samples, extracted from the Bayesian fit, was plotted.


```{r, fig.cap="Visualization of Regression Lines From the Posterior Distribution", include=T, message=F, fig.align='center', echo=F, results='hide'}
## Plots -----
library(rethinking) # load rethinking package for coloring lines easily  

# Before the plots can be drawn I need to reparametrize the models so I have no
# intercept

## First reparametrize the crude and adjusted models ----

# First the reparametrize the CRUDE model ----
# I add a 0 to get no intercept
crudeRe <- stan_glm(CogTest ~ 0 + soundscape_type,
                  data = d2, 
                  refresh = F, 
                  seed = 1995)

summary(crudeRe) # model inspection
posterior_interval(crudeRe) # model inspection

# Then the reparametrize the ADJUSTED model ----
# I add a 0 to get no intercept
adjustedRe <- stan_glm(CogTest ~ 0 + soundscape_type + guessed_purpose,
                  data = d2, 
                  refresh = F, 
                  seed = 1995)

summary(adjustedRe) # model inspection
posterior_interval(adjustedRe) # model inspection


## Now plots can be drawn ----
par(mfrow = c(1, 2), font = 1) # 1 column, 2 rows for the figure to be plotted


# create jitter ----
# jitter - random noisy variable with mean = 0 and sd = 0.05 that is added to 
# -------- the predictor to facilitate data point identification
jitter <- rnorm(length(as.numeric(d2$soundscape_type)), mean = 0, sd = 0.05)


## Plot the crude model ----
# NOTE: soundscape as numeric (1 = Urban, 2 = Natural)
plot(as.numeric(d2$soundscape_type) + jitter, 
     d2$CogTest, 
     pch = 21, 
     bg = "white", 
     axes = F, 
     xlab = "Soundscape type", 
     ylab = "Composite score", 
     ylim = c(-2, 2))

# add regression lines
cf0 <- crude$coefficients # extract coefficients
# draw regression line with lines function
lines(x = c(1, 2), y = c(cf0[1], cf0[1]+cf0[2]), lwd = 2, col = "black")

## add CI to figure 

# First extract posterior interval for Urban 
crudeciU <- posterior_interval(crudeRe)[1, ] 
# Then extract posterior interval for Natual  
crudeciS <- posterior_interval(crudeRe)[2, ] 

# draw CI bands
arrows(x0 = 1, x1 = 1, 
       y0 = crudeciU[1], y1 = crudeciU[2], 
       length = 0.1, angle = 90, code = 3, lty = 1, col = "black", lwd = 2)
arrows(x0 = 2, x1 = 2, 
       y0 = crudeciS[1], y1 = crudeciS[2], 
       length = 0.1, angle = 90, code = 3, lty = 1, col = "black", lwd = 2)


# add points
points(c(1, 2), 
       c(mean(d2$CogTest[d2$soundscape_type == "U"]), 
         mean(d2$CogTest[d2$soundscape_type == "N"])),
       pch = 21, bg = "skyblue", cex = 1.5, col = "purple4")
# Add x-axis labels
axis(1, at = c(1, 2), labels = c('Urban', 'Natural'))
# add y-axis
axis(2, at = c(-2:2), tick = T)

## Extract samples from crude model 
# Coercing a model to a data-frame returns a data-frame of posterior samples 
# One row per sample.
fits <- crude %>% # for the crude model
  as_tibble() %>% 
  rename(intercept = `(Intercept)`) %>% 
  select(-sigma)

## add regression estimates
for ( i in 1:20 ) {
  curve(fits$intercept[i] + 
          fits$soundscape_typeN[i]*(x-mean(as.numeric(d2$soundscape_type))),
         col=col.alpha("black", 0.2) , add=TRUE ,from = 1, to = 2)}

# add label to plot
mtext(text = "Crude model", side = 3)

# Add legend
points(0.92, 1.8, pch = 21, bg = "skyblue", cex = 1)
text(x = 0.9, y = 1.8, labels = "The arithmetic mean value", 
     pos = 4, cex = 0.55)

## Draw the adjusted model ----
# NOTE: soundscape as numeric (1 = Urban, 2 = Natural)
plot(as.numeric(d2$soundscape_type) + jitter, 
     d2$CogTest, 
     pch = 21, 
     bg = "white", 
     axes = F, 
     xlab = "Soundscape type", 
     ylab = "Composite score", 
     ylim = c(-2, 2))

# add regression line
cf1 <- adjusted$coefficients # extract coefficients 
lines(x = c(1, 2), y = c(cf1[1], cf1[1]+cf1[2]+cf1[3]), 
      lwd = 2, col = "black") # draw the regression line with the lines function

## add CI to figures

# extract posterior interval for Urban 
adjustedciU <- posterior_interval(adjustedRe)[1, ] 

# extract posterior interval for Natural 
adjustedciS <- posterior_interval(adjustedRe)[2, ]

# draw CI bands
arrows(x0 = 1, x1 = 1, 
       y0 = adjustedciU[1], y1 = adjustedciU[2], 
       length = 0.1, angle = 90, code = 3, lty = 1, col = "black", lwd = 2)
arrows(x0 = 2, x1 = 2, 
       y0 = adjustedciS[1], y1 = adjustedciS[2], 
       length = 0.1, angle = 90, code = 3, lty = 1, col = "black", lwd = 2)


# add points
points(c(1, 2), 
       c(mean(d2$CogTest[d2$soundscape_type == "U"]), 
         mean(d2$CogTest[d2$soundscape_type == "N"])),
       pch = 21, bg = "skyblue", cex = 1.5, col = "purple4")

# Add x-axis labels
axis(1, at = c(1, 2), labels = c('Urban', 'Natural'))
# add y-axis
axis(2, at = c(-2:2), tick = T)

## Extract samples from adjusted model 
# Coercing a model to a data-frame returns a data-frame of posterior samples 
# One row per sample.
fits2 <- adjusted %>% 
  as_tibble() %>% 
  rename(intercept = `(Intercept)`) %>% 
  select(-sigma)

## add regression estimates
for ( i in 1:20 ) {
  curve(fits2$intercept[i] + 
          fits2$soundscape_typeN[i]*(x-mean(as.numeric(d2$soundscape_type))),
         col=col.alpha("black", 0.2) , add=TRUE ,from = 1, to = 2)}

# add label
mtext(text = "Adjusted model", side = 3)

# Add legend
points(0.92, 1.8, pch = 21, bg = "skyblue", cex = 1)
text(x = 0.9, y = 1.8, labels = "The arithmetic mean value", 
     pos = 4, cex = 0.55)

```

As figure 1.2 shows, more uncertainty is in the *adjusted model* in comparison to the *crude model*. This result is somewhat surprising, given that naïvety was statistically controlled instead of omitting participants. However, this result can be explained by the fact that if participants **know** the purpose of the experiment, they are more likely to behave in a homogeneous manner. Thus, when we control for naïvety, participant response is more spread out. 

<br><br>




#### R packages

The following packages were used:

- rstanarm [@RstanarmBayesianApplied2020]
- ggpubr [@ggpubr2020]
- rethinking [@rethinkingRpack2020]
- psych [@psychRpack]
- tidyverse [@Tidyverse2019]
- knitr [@Knitr2014]
- kableExrta [@KableExtra2021]
- wordcountaddin [@wordcountaddin2021]


```{r word count, message=F, warning=F, include=F}
WC <- wordcountaddin::text_stats()
WC # Character count is 4328 and thus NOT < 4000, BUT I referenced all packages
# However, this function counts captions. 

# When the characters excluding tables and captions is counted, the character
# count, WITH SPACES is 3452. (as stated in the instructions)

## Thus the characther count is well under 4000 and there should not be a 
#  point deduction on the grounds of extending the 3k maximum since Mats had
#  already given a green light on the text, given it be under 4k.
```




<br>

# References 
<div id="refs"></div>

<br><br>

# Apendix I

```{r creation of sub-dataset, results='show', class.source = "fold-show", comment=""}
# read in data from OSF. It can be downloaded from: https://osf.io/5ub4c/
# alrenativly, I have uploaded it to my GitHub for convinience 
dor <- read.table("https://raw.githubusercontent.com/JonHlynsson/PSMT59-Statistics-I/master/data/d1_rawdata_from_osf.txt",
                  header = T, sep = ",")

# select appropriate columns 
dor_small <- dor[, c(1, 2, 12, 13, 16, 17, 26)] 
head(dor_small) # sanity check

# rename columns
colnames(dor_small) <- c("id", "soundscape_type", "bds_pre", "bds_post", "dnb_pre", 
                   "dnb_post", "guessed_purpose")
head(dor_small) #sanity check

# print d_full for comparison
head(d_full)
```

